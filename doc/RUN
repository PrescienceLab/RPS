Running RPS
===========

rps-help@cs.northwestern.edu

What it means to "Run RPS" is more complex that might be expected.  A
typical RPS build generates about 10 libraries and over 120
executables, not to mention another 30+ scripts.  Generally speaking,
one runs RPS by either running Prediction Components (ie, those codes
produced from the PredComp package) and Scripts (from the Scripts
package).

Setup
-----

If you did a simplified installation of RPS (make install), then
simply source $RPS_INSTALL_DIR/ENV from your .bashrc.  Otherwise, do
the following.

First set the environment variable RPS_DIR to the root of your RPS
tree.  The assumption here is that you are using an sh-derived shell.

export RPS_DIR=/home/pdinda/RPS-development

Next, export your OS and architecture:

export RPS_OS=LINUX
export RPS_ARCH=I386

Next, edit build/setup_rps_env as appropriate for your environment.
Then source it:

source build/setup_rps_env


Host load measurement
---------------------

Start up the measurement system on this host:

start_hostloadmeasure.pl

Get a measurement:

get_measurements_on.pl host

Plot measurements:

plot_measurements_and_predications_on.pl --rate=1 --nopred host

shut down the measurement system:

kill_hostloadmeasure.pl

Notice that there are also _on and _list versions of these scripts.


Host load prediction
--------------------

Start up the prediction system on this host:

start_hostloadpred.pl

Get a prediction:

get_predictions_on.pl host

Plot predictions:

plot_measurements_and_predictions_on.pl --rate=1 --nomeasure host

Plot both predictions and measurements:

plot_measurements_and_predictions_on.pl --rate=1 host

shut down the measurement system:

kill_hostloadpred.pl

Notice that there are also _on and _list versions of these scripts.


Java GUI
--------

Display measurements and predictions on a host:

run_gui_on.pl host



Network Flow Measurements and Predictions
-----------------------------------------

To do flow measurements, you will need to use the raw components
(flowbw*).  Notice that these will only work if you have Remos
installed and running and you built RPS with HAVE_REMOS=YES.

Alterantively, you can turn any command-line measuremeent tool into an
RPS measurement and prediction source using the following description.


Wrapping Any Tool to be an RPS Measurement and Prediction Source
----------------------------------------------------------------

Any tool that produces a stream of one (value) or two column
(timestamp, value) numerical output can be made into an RPS
measurement source, prediction source, or both.  

We provide a very simple tool for testing, gen_numbers.pl

Wrapping a tool as a measurement source with streaming and buffering
access modes (TCP-only): 

measurement_source.pl stream_port buffer_port numitems period TOOL

Wrapping a tool with a predictor that provides both streaming and
buffered access to predictions (TCP-only): 

prediction_source.pl num-steps-ahead control_port 
  stream_port buffer_port numitems period TOOL

By default, a managed AR(16) model is used.  You may also supply your
own choice of model using --model='....'.  The expectation is that it
is a managed model variant, however.

Wrapping a tool with a measurement source and a predictor 1that
provides both streaming and buffered access to measurements and
predictions (TCP-only): 

measurement_and_prediction_source.pl period measurement_stream_port 
  measurement_buffer_port num_measurements num_steps_ahead
  prediction_control_port prediction_stream_port
  prediction_buffer_port num_predictions TOOL

Example: predict windows disk usage using WatchTowerRPS.  (wt_disk.pl
is a wrapper provided in the WatchTowerRPS package):

measurement_and_prediction_source.pl ... wt_disk.pl


Wrapping any Tool With Streaming Wavelet Decomposition
------------------------------------------------------

Any tool that produces measurements, as described in the previous
section, can also be wrapped as an RPS "wavelet measurement source",
meaning that its output is transformed using a streaming wavelet
transform in to a set of signals, one for each level of the
transform.  

wavelet_measurement_source.pl stream_port|none buffer_port|none
       multicast_addr:port|none wavelet_type num_levels numitems
       period text-generator

Notice that you can supply a multicast destination as well.

You can get data from the buffer using get_wavelet_measurements_on.pl.

You can plot data from the buffer using plot_wavelet_source_on.pl.



Predictions of Task Running Time (Running Time Advisor)
-------------------------------------------------------

A host load predictor must be running on the host.

test_rta task_size confidence_level host



Real-time Scheduling Advisor
----------------------------

A host load predictor must be running on each of the hosts.

test_rtsa task_size confidence_level slack_factor host+


Offline Time Series Analysis and Prediction
-------------------------------------------

You can do offline analysis on any text file that has a one or two
column format.  You can transform into text files using the various
trace file translators (alpha_to_ascii, network_to_ascii, etc)/

The core offline time series prediction tool is ts_example, which is
relatively self explanatory.  Run it without arguments for help.


Offline Wavelet Analysis
------------------------

Tsunami includes a wide range of offline analysis tools.  Consult
the Tsunami TR for more information.


Use the individual components
-----------------------------

Consult README.PredComps and the RPS technical report.
